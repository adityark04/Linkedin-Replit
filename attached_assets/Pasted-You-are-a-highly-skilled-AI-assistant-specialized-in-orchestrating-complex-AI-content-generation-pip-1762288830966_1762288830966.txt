You are a highly skilled AI assistant specialized in orchestrating complex AI content generation pipelines. Your goal is to assist in building a "LinkedIn Post Optimizer" based on a detailed project breakdown. This tool is designed to transform user drafts into high-engagement LinkedIn posts without relying on external AI APIs. The workflow is structured in several key phases:

Phase 1 - Data Scraping:
- Implement a Python script using BeautifulSoup4 and requests/selenium to ethically scrape 500-1000 high-engagement LinkedIn posts from public profiles within the tech and marketing niches.
- Ensure compliance with robots.txt and avoid any login-required actions during scraping. Include delays between requests to minimize server load.
- Extract post details such as title, body, hashtags, and engagement metrics, storing cleaned data in a Pandas DataFrame or CSV file for training purposes.
- Augment the dataset with synthetic data by rule-based generation of 1000 drafts that mimic diverse tones, lengths, and demographic contexts to enrich the training corpus.

Phase 2 - Model Training:
Develop three distinct deep learning models optimized for content generation:
1. Transformer Model:
   - Construct a seq2seq Transformer using an encoder-decoder architecture to generate refined LinkedIn posts based on user drafts and metadata.
   - Train using scraped data, focusing on engaging hooks and hashtags. Use cross-entropy and perceptual loss for model optimization.
2. CNN Model:
   - Design a 1D-CNN architecture with Conv1D layers for feature extraction, emphasizing the generation of content optimized for local patterns.
   - Fine-tune with augmented, noisy data to handle variability in phrasing and header segmentation.
3. Hugging Face Model:
   - Fine-tune a compact Hugging Face model, such as DistilGPT-2 or T5-small, for high-quality content generation. 
   - Pre-train on the corpus, then refine using PEFT methodologies to optimize LinkedIn post draft refinement.

Phase 3 - Integration &amp; Evaluation:
- Ensemble the trained models to create a robust post-generation system. Implement weighted voting based on validation perplexity.
- Develop a Flask or Streamlit pipeline for model inference, allowing user inputs to undergo generation and ranking based on custom metrics like readability and sentiment analysis.
- Evaluate performance against held-out test data using metrics like BLEU, ROUGE-L, and human-like evaluation criteria, ensuring the system aligns with ethical guidelines.

Please proceed by crafting the initial Python script for LinkedIn post data scraping with fully-commented code. After completion, we can move to the subsequent phase, ensuring consistent integration and refinement across the project.